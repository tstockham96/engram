# HN Post — Feb 23, 2026

## Strategy Note

HN doesn't like daily self-promotion. Instead, post content that's genuinely interesting to the community with Engram as context, not the pitch. Today's angle: the technical finding about temporal context in memory systems.

---

## Option A: Technical blog-style submission

**Title:** Why AI memory systems fail at temporal questions (and a fix that took accuracy from 63% to 93%)

**URL:** https://www.engram.fyi/#/architecture (or GitHub README)

**Text (if self-post):**

I've been building an open-source memory system for AI agents (Engram) and running it against the LOCOMO benchmark (long-conversation memory eval from Snap Research).

For weeks I was stuck at ~63% accuracy. Full context (dumping the entire conversation) scored 88%. I assumed the gap was a retrieval problem — wrong memories being ranked above the right ones.

It wasn't. The right memories were being retrieved. The problem was temporal context.

LOCOMO conversations span months. Messages reference events with relative dates: "yesterday I went to the museum", "we're going camping next month", "I ran a charity race last Saturday." The benchmark has explicit timestamps for each conversation segment ("DATE: 2:20 pm on 5 July, 2023").

Full context gets these timestamps because it sees the raw conversation. My memory system was stripping them during ingestion. The memories stored "yesterday I went to the museum" with no anchor date. The LLM had no way to resolve "yesterday" to a specific date.

The fix was two changes:
1. Prefix each memory with its conversation timestamp: `[5 July 2023] Speaker: Yesterday I went to the museum`
2. Tell the answer-generation prompt to use bracketed dates to resolve relative references

Accuracy jumped from 63% to 93% on early results (eval still running across all 1,886 questions). Engram is now neck-and-neck with full context while using 30x fewer tokens.

The broader lesson: memory systems that strip temporal metadata during ingestion are throwing away information that's critical for answering "when" questions. This probably applies to RAG systems too — if your chunks don't carry their timestamps, you're leaving accuracy on the table.

Code: https://github.com/tstockham96/engram

---

## Option B: Link post (simpler, less risky)

**Title:** Engram: Open-source memory layer for AI agents with bi-temporal recall

**URL:** https://github.com/tstockham96/engram

(No text needed for link posts — the README does the talking.)

---

## Recommendation

Go with **Option A** if you want engagement and discussion. HN loves "here's a non-obvious thing I learned" posts. The temporal context insight is genuinely interesting and not just marketing.

Go with **Option B** if you want to play it safe and just get eyeballs on the repo.

**Don't post daily on HN** — that'll get you flagged. Once a week max for your own stuff. In between, comment on related threads (memory, RAG, MCP, agent architecture) and mention Engram organically when relevant.

## Better daily strategy

Instead of posting Engram directly every day:
- **Monday:** Post your own content (like today)
- **Tue-Sun:** Find and comment on related HN threads. Search for "AI memory", "RAG", "MCP server", "Claude Code", "agent context". Add value, mention Engram only when directly relevant.
- **Next Monday:** Post again with new results (final benchmark numbers, comparison page, etc.)

This builds credibility without looking spammy.
